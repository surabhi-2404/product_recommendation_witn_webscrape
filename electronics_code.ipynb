{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2f5792-efa7-4bbf-b268-df542190d829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\SURABHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Page 1\n",
      "Found products: 29\n",
      "âœ… Saved: 1\n",
      "âœ… Saved: 2\n",
      "âœ… Saved: 3\n",
      "âœ… Saved: 4\n",
      "âœ… Saved: 5\n",
      "âœ… Saved: 6\n",
      "âœ… Saved: 7\n",
      "âœ… Saved: 8\n",
      "âœ… Saved: 9\n",
      "âœ… Saved: 10\n",
      "âœ… Saved: 11\n",
      "âœ… Saved: 12\n",
      "âœ… Saved: 13\n",
      "âœ… Saved: 14\n",
      "âœ… Saved: 15\n",
      "âœ… Saved: 16\n",
      "âœ… Saved: 17\n",
      "âœ… Saved: 18\n",
      "âœ… Saved: 19\n",
      "âœ… Saved: 20\n",
      "âœ… Saved: 21\n",
      "âœ… Saved: 22\n",
      "âœ… Saved: 23\n",
      "âœ… Saved: 24\n",
      "âœ… Saved: 25\n",
      "âœ… Saved: 26\n",
      "âœ… Saved: 27\n",
      "âœ… Saved: 28\n",
      "âœ… Saved: 29\n",
      "\n",
      "ðŸ”„ Page 2\n",
      "Found products: 29\n",
      "âœ… Saved: 30\n",
      "âœ… Saved: 31\n",
      "âœ… Saved: 32\n",
      "âœ… Saved: 33\n",
      "âœ… Saved: 34\n",
      "âœ… Saved: 35\n",
      "âœ… Saved: 36\n",
      "âœ… Saved: 37\n",
      "âœ… Saved: 38\n",
      "âœ… Saved: 39\n",
      "âœ… Saved: 40\n",
      "âœ… Saved: 41\n",
      "âœ… Saved: 42\n",
      "âœ… Saved: 43\n",
      "âœ… Saved: 44\n",
      "âœ… Saved: 45\n",
      "âœ… Saved: 46\n",
      "âœ… Saved: 47\n",
      "âœ… Saved: 48\n",
      "âœ… Saved: 49\n",
      "âœ… Saved: 50\n",
      "âœ… Saved: 51\n",
      "âœ… Saved: 52\n",
      "âœ… Saved: 53\n",
      "âœ… Saved: 54\n",
      "âœ… Saved: 55\n",
      "âœ… Saved: 56\n",
      "âœ… Saved: 57\n",
      "\n",
      "ðŸ”„ Page 3\n",
      "Found products: 29\n",
      "âœ… Saved: 58\n",
      "âœ… Saved: 59\n",
      "âœ… Saved: 60\n",
      "âœ… Saved: 61\n",
      "âœ… Saved: 62\n",
      "âœ… Saved: 63\n",
      "âœ… Saved: 64\n",
      "âœ… Saved: 65\n",
      "âœ… Saved: 66\n",
      "âœ… Saved: 67\n",
      "âœ… Saved: 68\n",
      "âœ… Saved: 69\n",
      "âœ… Saved: 70\n",
      "âœ… Saved: 71\n",
      "âœ… Saved: 72\n",
      "âœ… Saved: 73\n",
      "âœ… Saved: 74\n",
      "âœ… Saved: 75\n",
      "âœ… Saved: 76\n",
      "âœ… Saved: 77\n",
      "âœ… Saved: 78\n",
      "âœ… Saved: 79\n",
      "âœ… Saved: 80\n",
      "âœ… Saved: 81\n",
      "âœ… Saved: 82\n",
      "âœ… Saved: 83\n",
      "\n",
      "ðŸ”„ Page 4\n",
      "Found products: 29\n",
      "âœ… Saved: 84\n",
      "âœ… Saved: 85\n",
      "âœ… Saved: 86\n",
      "âœ… Saved: 87\n",
      "âœ… Saved: 88\n",
      "âœ… Saved: 89\n",
      "âœ… Saved: 90\n",
      "âœ… Saved: 91\n",
      "âœ… Saved: 92\n",
      "âœ… Saved: 93\n",
      "âœ… Saved: 94\n",
      "âœ… Saved: 95\n",
      "âœ… Saved: 96\n",
      "âœ… Saved: 97\n",
      "âœ… Saved: 98\n",
      "âœ… Saved: 99\n",
      "âœ… Saved: 100\n",
      "\n",
      "ðŸŽ‰ DONE\n",
      "Clean file saved: AirConditionerselectronics_dataset_flipkart.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ===============================\n",
    "# NLTK SETUP\n",
    "# ===============================\n",
    "try:\n",
    "    nltk.data.find(\"sentiment/vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not text or len(text) < 10:\n",
    "        return \"Neutral\"\n",
    "    score = sia.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# REVIEW PARSER\n",
    "# ===============================\n",
    "def parse_review_block(raw_text):\n",
    "    data = {\n",
    "        \"overall_rating\": None,\n",
    "        \"total_ratings\": None,\n",
    "        \"total_reviews\": None,\n",
    "        \"rating_5\": 0,\n",
    "        \"rating_4\": 0,\n",
    "        \"rating_3\": 0,\n",
    "        \"rating_2\": 0,\n",
    "        \"rating_1\": 0,\n",
    "        \"review_text\": \"No review available\",\n",
    "        \"review_summary\": \"No review available\"\n",
    "    }\n",
    "\n",
    "    if not raw_text:\n",
    "        return data\n",
    "\n",
    "    m = re.search(r\"(\\d\\.\\d)\\â˜…\", raw_text)\n",
    "    if m:\n",
    "        data[\"overall_rating\"] = float(m.group(1))\n",
    "\n",
    "    m = re.search(r\"([\\d,]+)\\s*Ratings\\s*&\\s*([\\d,]+)\\s*Reviews\", raw_text)\n",
    "    if m:\n",
    "        data[\"total_ratings\"] = int(m.group(1).replace(\",\", \"\"))\n",
    "        data[\"total_reviews\"] = int(m.group(2).replace(\",\", \"\"))\n",
    "\n",
    "    def star_count(star):\n",
    "        m = re.search(rf\"{star}â˜…\\s*([\\d,]+)\", raw_text)\n",
    "        return int(m.group(1).replace(\",\", \"\")) if m else 0\n",
    "\n",
    "    data[\"rating_5\"] = star_count(5)\n",
    "    data[\"rating_4\"] = star_count(4)\n",
    "    data[\"rating_3\"] = star_count(3)\n",
    "    data[\"rating_2\"] = star_count(2)\n",
    "    data[\"rating_1\"] = star_count(1)\n",
    "\n",
    "    lines = [l.strip() for l in raw_text.split(\"\\n\") if len(l) > 20]\n",
    "    if lines:\n",
    "        data[\"review_text\"] = \" \".join(lines)\n",
    "        data[\"review_summary\"] = data[\"review_text\"][:120]\n",
    "\n",
    "    return data\n",
    "\n",
    "# ===============================\n",
    "# SENTIMENT LOGIC\n",
    "# ===============================\n",
    "def sentiment_from_rating(rating):\n",
    "    try:\n",
    "        rating = float(rating)\n",
    "    except:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if rating >= 4:\n",
    "        return \"Positive\"\n",
    "    elif rating >= 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "def hybrid_sentiment(text, rating, r5, r4, r1, r2):\n",
    "    text_sent = get_sentiment(text)\n",
    "    rating_sent = sentiment_from_rating(rating)\n",
    "\n",
    "    pos = r5 + r4\n",
    "    neg = r1 + r2\n",
    "\n",
    "    dist_sent = \"Neutral\"\n",
    "    if pos > neg:\n",
    "        dist_sent = \"Positive\"\n",
    "    elif neg > pos:\n",
    "        dist_sent = \"Negative\"\n",
    "\n",
    "    for s in [text_sent, rating_sent, dist_sent]:\n",
    "        if s != \"Neutral\":\n",
    "            return s\n",
    "    return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# SELENIUM SETUP\n",
    "# ===============================\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "SEARCH_QUERY = \"Air Conditioners\"\n",
    "TARGET_COUNT = 100\n",
    "CATEGORY = \"Electronics\"\n",
    "\n",
    "base_url = f\"https://www.flipkart.com/search?q={SEARCH_QUERY}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Close login popup\n",
    "try:\n",
    "    wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'âœ•')]\"))\n",
    "    ).click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = []\n",
    "seen_urls = set()\n",
    "page = 1\n",
    "saved_count = 0\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP (FIXED)\n",
    "# ===============================\n",
    "while saved_count < TARGET_COUNT:\n",
    "\n",
    "    print(f\"\\nðŸ”„ Page {page}\")\n",
    "\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollBy(0, 1500);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # âœ… WORKING SELECTOR\n",
    "    products = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//a[contains(@href,'/p/')]\"\n",
    "    )\n",
    "\n",
    "    print(\"Found products:\", len(products))\n",
    "\n",
    "    for a in products:\n",
    "        if saved_count >= TARGET_COUNT:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            link = a.get_attribute(\"href\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if not link or link in seen_urls:\n",
    "            continue\n",
    "        seen_urls.add(link)\n",
    "\n",
    "        try:\n",
    "            name = a.text.strip()\n",
    "            if not name:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Open product page\n",
    "        driver.execute_script(\"window.open(arguments[0]);\", link)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(4)\n",
    "\n",
    "        try:\n",
    "            price = driver.find_element(By.XPATH, \"//div[contains(text(),'â‚¹')]\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            rating = driver.find_element(By.XPATH, \"//div[contains(@class,'MKiFS6')]\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        raw_review = \"\"\n",
    "        try:\n",
    "            blocks = driver.find_elements(By.XPATH, \"//div[contains(@class,'xgU6qg')]\")\n",
    "            raw_review = \"\\n\".join([b.text for b in blocks[:5]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        parsed = parse_review_block(raw_review)\n",
    "\n",
    "        if parsed[\"review_text\"] == \"No review available\":\n",
    "            parsed[\"review_text\"] = name\n",
    "\n",
    "        sentiment = hybrid_sentiment(\n",
    "            parsed[\"review_text\"],\n",
    "            parsed[\"overall_rating\"],\n",
    "            parsed[\"rating_5\"],\n",
    "            parsed[\"rating_4\"],\n",
    "            parsed[\"rating_1\"],\n",
    "            parsed[\"rating_2\"]\n",
    "        )\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        saved_count += 1\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": name,\n",
    "            \"product_price\": price,\n",
    "             \"overall_rating\": rating,\n",
    "            \"product_url\": link,\n",
    "            \"category\": CATEGORY\n",
    "        })\n",
    "\n",
    "        print(f\"âœ… Saved: {saved_count}\")\n",
    "\n",
    "    page += 1\n",
    "    driver.get(f\"{base_url}&page={page}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# ===============================\n",
    "# SAVE CSV\n",
    "# ===============================\n",
    "pd.DataFrame(results).to_csv(\n",
    "    \"AirConditionerselectronics_dataset_flipkart.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nðŸŽ‰ DONE\")\n",
    "print(\"Clean file saved: AirConditionerselectronics_dataset_flipkart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d237d7-763d-4903-b9d5-686ef3d5d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\SURABHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Page 1\n",
      "Found products: 29\n",
      "âœ… Saved: 1\n",
      "âœ… Saved: 2\n",
      "âœ… Saved: 3\n",
      "âœ… Saved: 4\n",
      "âœ… Saved: 5\n",
      "âœ… Saved: 6\n",
      "âœ… Saved: 7\n",
      "âœ… Saved: 8\n",
      "âœ… Saved: 9\n",
      "âœ… Saved: 10\n",
      "âœ… Saved: 11\n",
      "âœ… Saved: 12\n",
      "âœ… Saved: 13\n",
      "âœ… Saved: 14\n",
      "âœ… Saved: 15\n",
      "âœ… Saved: 16\n",
      "âœ… Saved: 17\n",
      "âœ… Saved: 18\n",
      "âœ… Saved: 19\n",
      "âœ… Saved: 20\n",
      "âœ… Saved: 21\n",
      "âœ… Saved: 22\n",
      "âœ… Saved: 23\n",
      "âœ… Saved: 24\n",
      "âœ… Saved: 25\n",
      "âœ… Saved: 26\n",
      "âœ… Saved: 27\n",
      "âœ… Saved: 28\n",
      "âœ… Saved: 29\n",
      "\n",
      "ðŸ”„ Page 2\n",
      "Found products: 29\n",
      "âœ… Saved: 30\n",
      "âœ… Saved: 31\n",
      "âœ… Saved: 32\n",
      "âœ… Saved: 33\n",
      "âœ… Saved: 34\n",
      "âœ… Saved: 35\n",
      "âœ… Saved: 36\n",
      "âœ… Saved: 37\n",
      "âœ… Saved: 38\n",
      "âœ… Saved: 39\n",
      "âœ… Saved: 40\n",
      "âœ… Saved: 41\n",
      "âœ… Saved: 42\n",
      "âœ… Saved: 43\n",
      "âœ… Saved: 44\n",
      "âœ… Saved: 45\n",
      "âœ… Saved: 46\n",
      "âœ… Saved: 47\n",
      "âœ… Saved: 48\n",
      "âœ… Saved: 49\n",
      "âœ… Saved: 50\n",
      "âœ… Saved: 51\n",
      "âœ… Saved: 52\n",
      "âœ… Saved: 53\n",
      "âœ… Saved: 54\n",
      "âœ… Saved: 55\n",
      "âœ… Saved: 56\n",
      "\n",
      "ðŸ”„ Page 3\n",
      "Found products: 29\n",
      "âœ… Saved: 57\n",
      "âœ… Saved: 58\n",
      "âœ… Saved: 59\n",
      "âœ… Saved: 60\n",
      "âœ… Saved: 61\n",
      "âœ… Saved: 62\n",
      "âœ… Saved: 63\n",
      "âœ… Saved: 64\n",
      "âœ… Saved: 65\n",
      "âœ… Saved: 66\n",
      "âœ… Saved: 67\n",
      "âœ… Saved: 68\n",
      "âœ… Saved: 69\n",
      "âœ… Saved: 70\n",
      "âœ… Saved: 71\n",
      "âœ… Saved: 72\n",
      "âœ… Saved: 73\n",
      "âœ… Saved: 74\n",
      "âœ… Saved: 75\n",
      "âœ… Saved: 76\n",
      "âœ… Saved: 77\n",
      "âœ… Saved: 78\n",
      "âœ… Saved: 79\n",
      "âœ… Saved: 80\n",
      "âœ… Saved: 81\n",
      "âœ… Saved: 82\n",
      "\n",
      "ðŸ”„ Page 4\n",
      "Found products: 29\n",
      "âœ… Saved: 83\n",
      "âœ… Saved: 84\n",
      "âœ… Saved: 85\n",
      "âœ… Saved: 86\n",
      "âœ… Saved: 87\n",
      "âœ… Saved: 88\n",
      "âœ… Saved: 89\n",
      "âœ… Saved: 90\n",
      "âœ… Saved: 91\n",
      "âœ… Saved: 92\n",
      "âœ… Saved: 93\n",
      "âœ… Saved: 94\n",
      "âœ… Saved: 95\n",
      "âœ… Saved: 96\n",
      "âœ… Saved: 97\n",
      "âœ… Saved: 98\n",
      "âœ… Saved: 99\n",
      "âœ… Saved: 100\n",
      "\n",
      "ðŸŽ‰ DONE\n",
      "Clean file saved: laptop_dataset_flipkart.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ===============================\n",
    "# NLTK SETUP\n",
    "# ===============================\n",
    "try:\n",
    "    nltk.data.find(\"sentiment/vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not text or len(text) < 10:\n",
    "        return \"Neutral\"\n",
    "    score = sia.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# REVIEW PARSER\n",
    "# ===============================\n",
    "def parse_review_block(raw_text):\n",
    "    data = {\n",
    "        \"overall_rating\": None,\n",
    "        \"total_ratings\": None,\n",
    "        \"total_reviews\": None,\n",
    "        \"rating_5\": 0,\n",
    "        \"rating_4\": 0,\n",
    "        \"rating_3\": 0,\n",
    "        \"rating_2\": 0,\n",
    "        \"rating_1\": 0,\n",
    "        \"review_text\": \"No review available\",\n",
    "        \"review_summary\": \"No review available\"\n",
    "    }\n",
    "\n",
    "    if not raw_text:\n",
    "        return data\n",
    "\n",
    "    m = re.search(r\"(\\d\\.\\d)\\â˜…\", raw_text)\n",
    "    if m:\n",
    "        data[\"overall_rating\"] = float(m.group(1))\n",
    "\n",
    "    m = re.search(r\"([\\d,]+)\\s*Ratings\\s*&\\s*([\\d,]+)\\s*Reviews\", raw_text)\n",
    "    if m:\n",
    "        data[\"total_ratings\"] = int(m.group(1).replace(\",\", \"\"))\n",
    "        data[\"total_reviews\"] = int(m.group(2).replace(\",\", \"\"))\n",
    "\n",
    "    def star_count(star):\n",
    "        m = re.search(rf\"{star}â˜…\\s*([\\d,]+)\", raw_text)\n",
    "        return int(m.group(1).replace(\",\", \"\")) if m else 0\n",
    "\n",
    "    data[\"rating_5\"] = star_count(5)\n",
    "    data[\"rating_4\"] = star_count(4)\n",
    "    data[\"rating_3\"] = star_count(3)\n",
    "    data[\"rating_2\"] = star_count(2)\n",
    "    data[\"rating_1\"] = star_count(1)\n",
    "\n",
    "    lines = [l.strip() for l in raw_text.split(\"\\n\") if len(l) > 20]\n",
    "    if lines:\n",
    "        data[\"review_text\"] = \" \".join(lines)\n",
    "        data[\"review_summary\"] = data[\"review_text\"][:120]\n",
    "\n",
    "    return data\n",
    "\n",
    "# ===============================\n",
    "# SENTIMENT LOGIC\n",
    "# ===============================\n",
    "def sentiment_from_rating(rating):\n",
    "    try:\n",
    "        rating = float(rating)\n",
    "    except:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if rating >= 4:\n",
    "        return \"Positive\"\n",
    "    elif rating >= 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "def hybrid_sentiment(text, rating, r5, r4, r1, r2):\n",
    "    text_sent = get_sentiment(text)\n",
    "    rating_sent = sentiment_from_rating(rating)\n",
    "\n",
    "    pos = r5 + r4\n",
    "    neg = r1 + r2\n",
    "\n",
    "    dist_sent = \"Neutral\"\n",
    "    if pos > neg:\n",
    "        dist_sent = \"Positive\"\n",
    "    elif neg > pos:\n",
    "        dist_sent = \"Negative\"\n",
    "\n",
    "    for s in [text_sent, rating_sent, dist_sent]:\n",
    "        if s != \"Neutral\":\n",
    "            return s\n",
    "    return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# SELENIUM SETUP\n",
    "# ===============================\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "SEARCH_QUERY = \"Laptops\"\n",
    "TARGET_COUNT = 100\n",
    "CATEGORY = \"Electronics\"\n",
    "\n",
    "base_url = f\"https://www.flipkart.com/search?q={SEARCH_QUERY}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Close login popup\n",
    "try:\n",
    "    wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'âœ•')]\"))\n",
    "    ).click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = []\n",
    "seen_urls = set()\n",
    "page = 1\n",
    "saved_count = 0\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP (FIXED)\n",
    "# ===============================\n",
    "while saved_count < TARGET_COUNT:\n",
    "\n",
    "    print(f\"\\nðŸ”„ Page {page}\")\n",
    "\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollBy(0, 1500);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # âœ… WORKING SELECTOR\n",
    "    products = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//a[contains(@href,'/p/')]\"\n",
    "    )\n",
    "\n",
    "    print(\"Found products:\", len(products))\n",
    "\n",
    "    for a in products:\n",
    "        if saved_count >= TARGET_COUNT:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            link = a.get_attribute(\"href\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if not link or link in seen_urls:\n",
    "            continue\n",
    "        seen_urls.add(link)\n",
    "\n",
    "        try:\n",
    "            name = a.text.strip()\n",
    "            if not name:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Open product page\n",
    "        driver.execute_script(\"window.open(arguments[0]);\", link)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(4)\n",
    "\n",
    "        try:\n",
    "            price = driver.find_element(By.XPATH, \"//div[contains(text(),'â‚¹')]\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            rating = driver.find_element(By.XPATH, \"//div[contains(@class,'MKiFS6')]\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        raw_review = \"\"\n",
    "        try:\n",
    "            blocks = driver.find_elements(By.XPATH, \"//div[contains(@class,'xgU6qg')]\")\n",
    "            raw_review = \"\\n\".join([b.text for b in blocks[:5]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        parsed = parse_review_block(raw_review)\n",
    "\n",
    "        if parsed[\"review_text\"] == \"No review available\":\n",
    "            parsed[\"review_text\"] = name\n",
    "\n",
    "        sentiment = hybrid_sentiment(\n",
    "            parsed[\"review_text\"],\n",
    "            parsed[\"overall_rating\"],\n",
    "            parsed[\"rating_5\"],\n",
    "            parsed[\"rating_4\"],\n",
    "            parsed[\"rating_1\"],\n",
    "            parsed[\"rating_2\"]\n",
    "        )\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        saved_count += 1\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": name,\n",
    "            \"product_price\": price,\n",
    "            \"overall_rating\": rating,\n",
    "            \"product_url\": link,\n",
    "            \"category\": CATEGORY\n",
    "        })\n",
    "\n",
    "        print(f\"âœ… Saved: {saved_count}\")\n",
    "\n",
    "    page += 1\n",
    "    driver.get(f\"{base_url}&page={page}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# ===============================\n",
    "# SAVE CSV\n",
    "# ===============================\n",
    "pd.DataFrame(results).to_csv(\n",
    "    \"laptop_dataset_flipkart.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nðŸŽ‰ DONE\")\n",
    "print(\"Clean file saved: laptop_dataset_flipkart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddbaf649-28a1-48d5-819b-cd1de59f5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\SURABHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Page 1\n",
      "Found products: 29\n",
      "âœ… Saved: 1\n",
      "âœ… Saved: 2\n",
      "âœ… Saved: 3\n",
      "âœ… Saved: 4\n",
      "âœ… Saved: 5\n",
      "âœ… Saved: 6\n",
      "âœ… Saved: 7\n",
      "âœ… Saved: 8\n",
      "âœ… Saved: 9\n",
      "âœ… Saved: 10\n",
      "âœ… Saved: 11\n",
      "âœ… Saved: 12\n",
      "âœ… Saved: 13\n",
      "âœ… Saved: 14\n",
      "âœ… Saved: 15\n",
      "âœ… Saved: 16\n",
      "âœ… Saved: 17\n",
      "âœ… Saved: 18\n",
      "âœ… Saved: 19\n",
      "âœ… Saved: 20\n",
      "âœ… Saved: 21\n",
      "âœ… Saved: 22\n",
      "âœ… Saved: 23\n",
      "âœ… Saved: 24\n",
      "âœ… Saved: 25\n",
      "âœ… Saved: 26\n",
      "âœ… Saved: 27\n",
      "âœ… Saved: 28\n",
      "âœ… Saved: 29\n",
      "\n",
      "ðŸ”„ Page 2\n",
      "Found products: 29\n",
      "âœ… Saved: 30\n",
      "âœ… Saved: 31\n",
      "âœ… Saved: 32\n",
      "âœ… Saved: 33\n",
      "âœ… Saved: 34\n",
      "âœ… Saved: 35\n",
      "âœ… Saved: 36\n",
      "âœ… Saved: 37\n",
      "âœ… Saved: 38\n",
      "âœ… Saved: 39\n",
      "âœ… Saved: 40\n",
      "âœ… Saved: 41\n",
      "âœ… Saved: 42\n",
      "âœ… Saved: 43\n",
      "âœ… Saved: 44\n",
      "âœ… Saved: 45\n",
      "âœ… Saved: 46\n",
      "âœ… Saved: 47\n",
      "âœ… Saved: 48\n",
      "âœ… Saved: 49\n",
      "âœ… Saved: 50\n",
      "âœ… Saved: 51\n",
      "âœ… Saved: 52\n",
      "âœ… Saved: 53\n",
      "âœ… Saved: 54\n",
      "âœ… Saved: 55\n",
      "âœ… Saved: 56\n",
      "âœ… Saved: 57\n",
      "âœ… Saved: 58\n",
      "\n",
      "ðŸ”„ Page 3\n",
      "Found products: 29\n",
      "âœ… Saved: 59\n",
      "âœ… Saved: 60\n",
      "âœ… Saved: 61\n",
      "âœ… Saved: 62\n",
      "âœ… Saved: 63\n",
      "âœ… Saved: 64\n",
      "âœ… Saved: 65\n",
      "âœ… Saved: 66\n",
      "âœ… Saved: 67\n",
      "âœ… Saved: 68\n",
      "âœ… Saved: 69\n",
      "âœ… Saved: 70\n",
      "âœ… Saved: 71\n",
      "âœ… Saved: 72\n",
      "âœ… Saved: 73\n",
      "âœ… Saved: 74\n",
      "âœ… Saved: 75\n",
      "âœ… Saved: 76\n",
      "âœ… Saved: 77\n",
      "âœ… Saved: 78\n",
      "âœ… Saved: 79\n",
      "âœ… Saved: 80\n",
      "âœ… Saved: 81\n",
      "âœ… Saved: 82\n",
      "âœ… Saved: 83\n",
      "âœ… Saved: 84\n",
      "âœ… Saved: 85\n",
      "âœ… Saved: 86\n",
      "\n",
      "ðŸ”„ Page 4\n",
      "Found products: 29\n",
      "âœ… Saved: 87\n",
      "âœ… Saved: 88\n",
      "âœ… Saved: 89\n",
      "âœ… Saved: 90\n",
      "âœ… Saved: 91\n",
      "âœ… Saved: 92\n",
      "âœ… Saved: 93\n",
      "âœ… Saved: 94\n",
      "âœ… Saved: 95\n",
      "âœ… Saved: 96\n",
      "âœ… Saved: 97\n",
      "âœ… Saved: 98\n",
      "âœ… Saved: 99\n",
      "âœ… Saved: 100\n",
      "\n",
      "ðŸŽ‰ DONE\n",
      "Clean file saved: Refrigerators_dataset_flipkart.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ===============================\n",
    "# NLTK SETUP\n",
    "# ===============================\n",
    "try:\n",
    "    nltk.data.find(\"sentiment/vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not text or len(text) < 10:\n",
    "        return \"Neutral\"\n",
    "    score = sia.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# REVIEW PARSER\n",
    "# ===============================\n",
    "def parse_review_block(raw_text):\n",
    "    data = {\n",
    "        \"overall_rating\": None,\n",
    "        \"total_ratings\": None,\n",
    "        \"total_reviews\": None,\n",
    "        \"rating_5\": 0,\n",
    "        \"rating_4\": 0,\n",
    "        \"rating_3\": 0,\n",
    "        \"rating_2\": 0,\n",
    "        \"rating_1\": 0,\n",
    "        \"review_text\": \"No review available\",\n",
    "        \"review_summary\": \"No review available\"\n",
    "    }\n",
    "\n",
    "    if not raw_text:\n",
    "        return data\n",
    "\n",
    "    m = re.search(r\"(\\d\\.\\d)\\â˜…\", raw_text)\n",
    "    if m:\n",
    "        data[\"overall_rating\"] = float(m.group(1))\n",
    "\n",
    "    m = re.search(r\"([\\d,]+)\\s*Ratings\\s*&\\s*([\\d,]+)\\s*Reviews\", raw_text)\n",
    "    if m:\n",
    "        data[\"total_ratings\"] = int(m.group(1).replace(\",\", \"\"))\n",
    "        data[\"total_reviews\"] = int(m.group(2).replace(\",\", \"\"))\n",
    "\n",
    "    def star_count(star):\n",
    "        m = re.search(rf\"{star}â˜…\\s*([\\d,]+)\", raw_text)\n",
    "        return int(m.group(1).replace(\",\", \"\")) if m else 0\n",
    "\n",
    "    data[\"rating_5\"] = star_count(5)\n",
    "    data[\"rating_4\"] = star_count(4)\n",
    "    data[\"rating_3\"] = star_count(3)\n",
    "    data[\"rating_2\"] = star_count(2)\n",
    "    data[\"rating_1\"] = star_count(1)\n",
    "\n",
    "    lines = [l.strip() for l in raw_text.split(\"\\n\") if len(l) > 20]\n",
    "    if lines:\n",
    "        data[\"review_text\"] = \" \".join(lines)\n",
    "        data[\"review_summary\"] = data[\"review_text\"][:120]\n",
    "\n",
    "    return data\n",
    "\n",
    "# ===============================\n",
    "# SENTIMENT LOGIC\n",
    "# ===============================\n",
    "def sentiment_from_rating(rating):\n",
    "    try:\n",
    "        rating = float(rating)\n",
    "    except:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if rating >= 4:\n",
    "        return \"Positive\"\n",
    "    elif rating >= 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "def hybrid_sentiment(text, rating, r5, r4, r1, r2):\n",
    "    text_sent = get_sentiment(text)\n",
    "    rating_sent = sentiment_from_rating(rating)\n",
    "\n",
    "    pos = r5 + r4\n",
    "    neg = r1 + r2\n",
    "\n",
    "    dist_sent = \"Neutral\"\n",
    "    if pos > neg:\n",
    "        dist_sent = \"Positive\"\n",
    "    elif neg > pos:\n",
    "        dist_sent = \"Negative\"\n",
    "\n",
    "    for s in [text_sent, rating_sent, dist_sent]:\n",
    "        if s != \"Neutral\":\n",
    "            return s\n",
    "    return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# SELENIUM SETUP\n",
    "# ===============================\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "SEARCH_QUERY = \"Refrigerators\"\n",
    "TARGET_COUNT = 100\n",
    "CATEGORY = \"Electronics\"\n",
    "\n",
    "base_url = f\"https://www.flipkart.com/search?q={SEARCH_QUERY}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Close login popup\n",
    "try:\n",
    "    wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'âœ•')]\"))\n",
    "    ).click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = []\n",
    "seen_urls = set()\n",
    "page = 1\n",
    "saved_count = 0\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP (FIXED)\n",
    "# ===============================\n",
    "while saved_count < TARGET_COUNT:\n",
    "\n",
    "    print(f\"\\nðŸ”„ Page {page}\")\n",
    "\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollBy(0, 1500);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # âœ… WORKING SELECTOR\n",
    "    products = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//a[contains(@href,'/p/')]\"\n",
    "    )\n",
    "\n",
    "    print(\"Found products:\", len(products))\n",
    "\n",
    "    for a in products:\n",
    "        if saved_count >= TARGET_COUNT:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            link = a.get_attribute(\"href\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if not link or link in seen_urls:\n",
    "            continue\n",
    "        seen_urls.add(link)\n",
    "\n",
    "        try:\n",
    "            name = a.text.strip()\n",
    "            if not name:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Open product page\n",
    "        driver.execute_script(\"window.open(arguments[0]);\", link)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(4)\n",
    "\n",
    "        try:\n",
    "            price = driver.find_element(By.XPATH, \"//div[contains(text(),'â‚¹')]\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            rating = driver.find_element(By.XPATH, \"//div[contains(@class,'MKiFS6')]\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        raw_review = \"\"\n",
    "        try:\n",
    "            blocks = driver.find_elements(By.XPATH, \"//div[contains(@class,'xgU6qg')]\")\n",
    "            raw_review = \"\\n\".join([b.text for b in blocks[:5]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        parsed = parse_review_block(raw_review)\n",
    "\n",
    "        if parsed[\"review_text\"] == \"No review available\":\n",
    "            parsed[\"review_text\"] = name\n",
    "\n",
    "        sentiment = hybrid_sentiment(\n",
    "            parsed[\"review_text\"],\n",
    "            parsed[\"overall_rating\"],\n",
    "            parsed[\"rating_5\"],\n",
    "            parsed[\"rating_4\"],\n",
    "            parsed[\"rating_1\"],\n",
    "            parsed[\"rating_2\"]\n",
    "        )\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        saved_count += 1\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": name,\n",
    "            \"product_price\": price,\n",
    "            \"overall_rating\": rating,\n",
    "            \"product_url\": link,\n",
    "            \"category\": CATEGORY\n",
    "        })\n",
    "\n",
    "        print(f\"âœ… Saved: {saved_count}\")\n",
    "\n",
    "    page += 1\n",
    "    driver.get(f\"{base_url}&page={page}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# ===============================\n",
    "# SAVE CSV\n",
    "# ===============================\n",
    "pd.DataFrame(results).to_csv(\n",
    "    \"refrigerators_dataset_flipkart.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nðŸŽ‰ DONE\")\n",
    "print(\"Clean file saved: Refrigerators_dataset_flipkart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f69bdc2-7740-407f-aa9c-06d460d9f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\SURABHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Page 1\n",
      "Found products: 29\n",
      "âœ… Saved: 1\n",
      "âœ… Saved: 2\n",
      "âœ… Saved: 3\n",
      "âœ… Saved: 4\n",
      "âœ… Saved: 5\n",
      "âœ… Saved: 6\n",
      "âœ… Saved: 7\n",
      "âœ… Saved: 8\n",
      "âœ… Saved: 9\n",
      "âœ… Saved: 10\n",
      "âœ… Saved: 11\n",
      "âœ… Saved: 12\n",
      "âœ… Saved: 13\n",
      "âœ… Saved: 14\n",
      "âœ… Saved: 15\n",
      "âœ… Saved: 16\n",
      "âœ… Saved: 17\n",
      "âœ… Saved: 18\n",
      "âœ… Saved: 19\n",
      "âœ… Saved: 20\n",
      "âœ… Saved: 21\n",
      "âœ… Saved: 22\n",
      "âœ… Saved: 23\n",
      "âœ… Saved: 24\n",
      "âœ… Saved: 25\n",
      "âœ… Saved: 26\n",
      "âœ… Saved: 27\n",
      "âœ… Saved: 28\n",
      "âœ… Saved: 29\n",
      "\n",
      "ðŸ”„ Page 2\n",
      "Found products: 29\n",
      "âœ… Saved: 30\n",
      "âœ… Saved: 31\n",
      "âœ… Saved: 32\n",
      "âœ… Saved: 33\n",
      "âœ… Saved: 34\n",
      "âœ… Saved: 35\n",
      "âœ… Saved: 36\n",
      "âœ… Saved: 37\n",
      "âœ… Saved: 38\n",
      "âœ… Saved: 39\n",
      "âœ… Saved: 40\n",
      "âœ… Saved: 41\n",
      "âœ… Saved: 42\n",
      "âœ… Saved: 43\n",
      "âœ… Saved: 44\n",
      "âœ… Saved: 45\n",
      "âœ… Saved: 46\n",
      "âœ… Saved: 47\n",
      "âœ… Saved: 48\n",
      "âœ… Saved: 49\n",
      "âœ… Saved: 50\n",
      "âœ… Saved: 51\n",
      "âœ… Saved: 52\n",
      "âœ… Saved: 53\n",
      "âœ… Saved: 54\n",
      "âœ… Saved: 55\n",
      "âœ… Saved: 56\n",
      "âœ… Saved: 57\n",
      "âœ… Saved: 58\n",
      "\n",
      "ðŸ”„ Page 3\n",
      "Found products: 29\n",
      "âœ… Saved: 59\n",
      "âœ… Saved: 60\n",
      "âœ… Saved: 61\n",
      "âœ… Saved: 62\n",
      "âœ… Saved: 63\n",
      "âœ… Saved: 64\n",
      "âœ… Saved: 65\n",
      "âœ… Saved: 66\n",
      "âœ… Saved: 67\n",
      "âœ… Saved: 68\n",
      "âœ… Saved: 69\n",
      "âœ… Saved: 70\n",
      "âœ… Saved: 71\n",
      "âœ… Saved: 72\n",
      "âœ… Saved: 73\n",
      "âœ… Saved: 74\n",
      "âœ… Saved: 75\n",
      "âœ… Saved: 76\n",
      "âœ… Saved: 77\n",
      "âœ… Saved: 78\n",
      "âœ… Saved: 79\n",
      "âœ… Saved: 80\n",
      "âœ… Saved: 81\n",
      "âœ… Saved: 82\n",
      "âœ… Saved: 83\n",
      "âœ… Saved: 84\n",
      "âœ… Saved: 85\n",
      "âœ… Saved: 86\n",
      "\n",
      "ðŸ”„ Page 4\n",
      "Found products: 29\n",
      "âœ… Saved: 87\n",
      "âœ… Saved: 88\n",
      "âœ… Saved: 89\n",
      "âœ… Saved: 90\n",
      "âœ… Saved: 91\n",
      "âœ… Saved: 92\n",
      "âœ… Saved: 93\n",
      "âœ… Saved: 94\n",
      "âœ… Saved: 95\n",
      "âœ… Saved: 96\n",
      "âœ… Saved: 97\n",
      "âœ… Saved: 98\n",
      "âœ… Saved: 99\n",
      "âœ… Saved: 100\n",
      "\n",
      "ðŸŽ‰ DONE\n",
      "Clean file saved: Smartphones_dataset_flipkart.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ===============================\n",
    "# NLTK SETUP\n",
    "# ===============================\n",
    "try:\n",
    "    nltk.data.find(\"sentiment/vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not text or len(text) < 10:\n",
    "        return \"Neutral\"\n",
    "    score = sia.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# REVIEW PARSER\n",
    "# ===============================\n",
    "def parse_review_block(raw_text):\n",
    "    data = {\n",
    "        \"overall_rating\": None,\n",
    "        \"total_ratings\": None,\n",
    "        \"total_reviews\": None,\n",
    "        \"rating_5\": 0,\n",
    "        \"rating_4\": 0,\n",
    "        \"rating_3\": 0,\n",
    "        \"rating_2\": 0,\n",
    "        \"rating_1\": 0,\n",
    "        \"review_text\": \"No review available\",\n",
    "        \"review_summary\": \"No review available\"\n",
    "    }\n",
    "\n",
    "    if not raw_text:\n",
    "        return data\n",
    "\n",
    "    m = re.search(r\"(\\d\\.\\d)\\â˜…\", raw_text)\n",
    "    if m:\n",
    "        data[\"overall_rating\"] = float(m.group(1))\n",
    "\n",
    "    m = re.search(r\"([\\d,]+)\\s*Ratings\\s*&\\s*([\\d,]+)\\s*Reviews\", raw_text)\n",
    "    if m:\n",
    "        data[\"total_ratings\"] = int(m.group(1).replace(\",\", \"\"))\n",
    "        data[\"total_reviews\"] = int(m.group(2).replace(\",\", \"\"))\n",
    "\n",
    "    def star_count(star):\n",
    "        m = re.search(rf\"{star}â˜…\\s*([\\d,]+)\", raw_text)\n",
    "        return int(m.group(1).replace(\",\", \"\")) if m else 0\n",
    "\n",
    "    data[\"rating_5\"] = star_count(5)\n",
    "    data[\"rating_4\"] = star_count(4)\n",
    "    data[\"rating_3\"] = star_count(3)\n",
    "    data[\"rating_2\"] = star_count(2)\n",
    "    data[\"rating_1\"] = star_count(1)\n",
    "\n",
    "    lines = [l.strip() for l in raw_text.split(\"\\n\") if len(l) > 20]\n",
    "    if lines:\n",
    "        data[\"review_text\"] = \" \".join(lines)\n",
    "        data[\"review_summary\"] = data[\"review_text\"][:120]\n",
    "\n",
    "    return data\n",
    "\n",
    "# ===============================\n",
    "# SENTIMENT LOGIC\n",
    "# ===============================\n",
    "def sentiment_from_rating(rating):\n",
    "    try:\n",
    "        rating = float(rating)\n",
    "    except:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if rating >= 4:\n",
    "        return \"Positive\"\n",
    "    elif rating >= 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "def hybrid_sentiment(text, rating, r5, r4, r1, r2):\n",
    "    text_sent = get_sentiment(text)\n",
    "    rating_sent = sentiment_from_rating(rating)\n",
    "\n",
    "    pos = r5 + r4\n",
    "    neg = r1 + r2\n",
    "\n",
    "    dist_sent = \"Neutral\"\n",
    "    if pos > neg:\n",
    "        dist_sent = \"Positive\"\n",
    "    elif neg > pos:\n",
    "        dist_sent = \"Negative\"\n",
    "\n",
    "    for s in [text_sent, rating_sent, dist_sent]:\n",
    "        if s != \"Neutral\":\n",
    "            return s\n",
    "    return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# SELENIUM SETUP\n",
    "# ===============================\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "SEARCH_QUERY = \"Smartphones\"\n",
    "TARGET_COUNT = 100\n",
    "CATEGORY = \"Electronics\"\n",
    "\n",
    "base_url = f\"https://www.flipkart.com/search?q={SEARCH_QUERY}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Close login popup\n",
    "try:\n",
    "    wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'âœ•')]\"))\n",
    "    ).click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = []\n",
    "seen_urls = set()\n",
    "page = 1\n",
    "saved_count = 0\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP (FIXED)\n",
    "# ===============================\n",
    "while saved_count < TARGET_COUNT:\n",
    "\n",
    "    print(f\"\\nðŸ”„ Page {page}\")\n",
    "\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollBy(0, 1500);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # âœ… WORKING SELECTOR\n",
    "    products = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//a[contains(@href,'/p/')]\"\n",
    "    )\n",
    "\n",
    "    print(\"Found products:\", len(products))\n",
    "\n",
    "    for a in products:\n",
    "        if saved_count >= TARGET_COUNT:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            link = a.get_attribute(\"href\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if not link or link in seen_urls:\n",
    "            continue\n",
    "        seen_urls.add(link)\n",
    "\n",
    "        try:\n",
    "            name = a.text.strip()\n",
    "            if not name:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Open product page\n",
    "        driver.execute_script(\"window.open(arguments[0]);\", link)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(4)\n",
    "\n",
    "        try:\n",
    "            price = driver.find_element(By.XPATH, \"//div[contains(text(),'â‚¹')]\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            rating = driver.find_element(By.XPATH, \"//div[contains(@class,'MKiFS6')]\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        raw_review = \"\"\n",
    "        try:\n",
    "            blocks = driver.find_elements(By.XPATH, \"//div[contains(@class,'xgU6qg')]\")\n",
    "            raw_review = \"\\n\".join([b.text for b in blocks[:5]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        parsed = parse_review_block(raw_review)\n",
    "\n",
    "        if parsed[\"review_text\"] == \"No review available\":\n",
    "            parsed[\"review_text\"] = name\n",
    "\n",
    "        sentiment = hybrid_sentiment(\n",
    "            parsed[\"review_text\"],\n",
    "            parsed[\"overall_rating\"],\n",
    "            parsed[\"rating_5\"],\n",
    "            parsed[\"rating_4\"],\n",
    "            parsed[\"rating_1\"],\n",
    "            parsed[\"rating_2\"]\n",
    "        )\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        saved_count += 1\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": name,\n",
    "            \"product_price\": price,\n",
    "            \"overall_rating\": rating,\n",
    "            \"product_url\": link,\n",
    "            \"category\": CATEGORY\n",
    "        })\n",
    "\n",
    "        print(f\"âœ… Saved: {saved_count}\")\n",
    "\n",
    "    page += 1\n",
    "    driver.get(f\"{base_url}&page={page}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# ===============================\n",
    "# SAVE CSV\n",
    "# ===============================\n",
    "pd.DataFrame(results).to_csv(\n",
    "    \"smartphones_dataset_flipkart.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nðŸŽ‰ DONE\")\n",
    "print(\"Clean file saved: Smartphones_dataset_flipkart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09452f6-813b-46f5-af76-54f689d80b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\SURABHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Page 1\n",
      "Found products: 29\n",
      "âœ… Saved: 1\n",
      "âœ… Saved: 2\n",
      "âœ… Saved: 3\n",
      "âœ… Saved: 4\n",
      "âœ… Saved: 5\n",
      "âœ… Saved: 6\n",
      "âœ… Saved: 7\n",
      "âœ… Saved: 8\n",
      "âœ… Saved: 9\n",
      "âœ… Saved: 10\n",
      "âœ… Saved: 11\n",
      "âœ… Saved: 12\n",
      "âœ… Saved: 13\n",
      "âœ… Saved: 14\n",
      "âœ… Saved: 15\n",
      "âœ… Saved: 16\n",
      "âœ… Saved: 17\n",
      "âœ… Saved: 18\n",
      "âœ… Saved: 19\n",
      "âœ… Saved: 20\n",
      "âœ… Saved: 21\n",
      "âœ… Saved: 22\n",
      "âœ… Saved: 23\n",
      "âœ… Saved: 24\n",
      "âœ… Saved: 25\n",
      "âœ… Saved: 26\n",
      "âœ… Saved: 27\n",
      "âœ… Saved: 28\n",
      "âœ… Saved: 29\n",
      "\n",
      "ðŸ”„ Page 2\n",
      "Found products: 29\n",
      "âœ… Saved: 30\n",
      "âœ… Saved: 31\n",
      "âœ… Saved: 32\n",
      "âœ… Saved: 33\n",
      "âœ… Saved: 34\n",
      "âœ… Saved: 35\n",
      "âœ… Saved: 36\n",
      "âœ… Saved: 37\n",
      "âœ… Saved: 38\n",
      "âœ… Saved: 39\n",
      "âœ… Saved: 40\n",
      "âœ… Saved: 41\n",
      "âœ… Saved: 42\n",
      "âœ… Saved: 43\n",
      "âœ… Saved: 44\n",
      "âœ… Saved: 45\n",
      "âœ… Saved: 46\n",
      "âœ… Saved: 47\n",
      "âœ… Saved: 48\n",
      "âœ… Saved: 49\n",
      "âœ… Saved: 50\n",
      "âœ… Saved: 51\n",
      "âœ… Saved: 52\n",
      "âœ… Saved: 53\n",
      "âœ… Saved: 54\n",
      "âœ… Saved: 55\n",
      "âœ… Saved: 56\n",
      "âœ… Saved: 57\n",
      "âœ… Saved: 58\n",
      "\n",
      "ðŸ”„ Page 3\n",
      "Found products: 29\n",
      "âœ… Saved: 59\n",
      "âœ… Saved: 60\n",
      "âœ… Saved: 61\n",
      "âœ… Saved: 62\n",
      "âœ… Saved: 63\n",
      "âœ… Saved: 64\n",
      "âœ… Saved: 65\n",
      "âœ… Saved: 66\n",
      "âœ… Saved: 67\n",
      "âœ… Saved: 68\n",
      "âœ… Saved: 69\n",
      "âœ… Saved: 70\n",
      "âœ… Saved: 71\n",
      "âœ… Saved: 72\n",
      "âœ… Saved: 73\n",
      "âœ… Saved: 74\n",
      "âœ… Saved: 75\n",
      "âœ… Saved: 76\n",
      "âœ… Saved: 77\n",
      "âœ… Saved: 78\n",
      "âœ… Saved: 79\n",
      "âœ… Saved: 80\n",
      "âœ… Saved: 81\n",
      "âœ… Saved: 82\n",
      "âœ… Saved: 83\n",
      "âœ… Saved: 84\n",
      "âœ… Saved: 85\n",
      "âœ… Saved: 86\n",
      "\n",
      "ðŸ”„ Page 4\n",
      "Found products: 29\n",
      "âœ… Saved: 87\n",
      "âœ… Saved: 88\n",
      "âœ… Saved: 89\n",
      "âœ… Saved: 90\n",
      "âœ… Saved: 91\n",
      "âœ… Saved: 92\n",
      "âœ… Saved: 93\n",
      "âœ… Saved: 94\n",
      "âœ… Saved: 95\n",
      "âœ… Saved: 96\n",
      "âœ… Saved: 97\n",
      "âœ… Saved: 98\n",
      "âœ… Saved: 99\n",
      "âœ… Saved: 100\n",
      "\n",
      "ðŸŽ‰ DONE\n",
      "Clean file saved: Televisions_dataset_flipkart.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ===============================\n",
    "# NLTK SETUP\n",
    "# ===============================\n",
    "try:\n",
    "    nltk.data.find(\"sentiment/vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not text or len(text) < 10:\n",
    "        return \"Neutral\"\n",
    "    score = sia.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# REVIEW PARSER\n",
    "# ===============================\n",
    "def parse_review_block(raw_text):\n",
    "    data = {\n",
    "        \"overall_rating\": None,\n",
    "        \"total_ratings\": None,\n",
    "        \"total_reviews\": None,\n",
    "        \"rating_5\": 0,\n",
    "        \"rating_4\": 0,\n",
    "        \"rating_3\": 0,\n",
    "        \"rating_2\": 0,\n",
    "        \"rating_1\": 0,\n",
    "        \"review_text\": \"No review available\",\n",
    "        \"review_summary\": \"No review available\"\n",
    "    }\n",
    "\n",
    "    if not raw_text:\n",
    "        return data\n",
    "\n",
    "    m = re.search(r\"(\\d\\.\\d)\\â˜…\", raw_text)\n",
    "    if m:\n",
    "        data[\"overall_rating\"] = float(m.group(1))\n",
    "\n",
    "    m = re.search(r\"([\\d,]+)\\s*Ratings\\s*&\\s*([\\d,]+)\\s*Reviews\", raw_text)\n",
    "    if m:\n",
    "        data[\"total_ratings\"] = int(m.group(1).replace(\",\", \"\"))\n",
    "        data[\"total_reviews\"] = int(m.group(2).replace(\",\", \"\"))\n",
    "\n",
    "    def star_count(star):\n",
    "        m = re.search(rf\"{star}â˜…\\s*([\\d,]+)\", raw_text)\n",
    "        return int(m.group(1).replace(\",\", \"\")) if m else 0\n",
    "\n",
    "    data[\"rating_5\"] = star_count(5)\n",
    "    data[\"rating_4\"] = star_count(4)\n",
    "    data[\"rating_3\"] = star_count(3)\n",
    "    data[\"rating_2\"] = star_count(2)\n",
    "    data[\"rating_1\"] = star_count(1)\n",
    "\n",
    "    lines = [l.strip() for l in raw_text.split(\"\\n\") if len(l) > 20]\n",
    "    if lines:\n",
    "        data[\"review_text\"] = \" \".join(lines)\n",
    "        data[\"review_summary\"] = data[\"review_text\"][:120]\n",
    "\n",
    "    return data\n",
    "\n",
    "# ===============================\n",
    "# SENTIMENT LOGIC\n",
    "# ===============================\n",
    "def sentiment_from_rating(rating):\n",
    "    try:\n",
    "        rating = float(rating)\n",
    "    except:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if rating >= 4:\n",
    "        return \"Positive\"\n",
    "    elif rating >= 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "def hybrid_sentiment(text, rating, r5, r4, r1, r2):\n",
    "    text_sent = get_sentiment(text)\n",
    "    rating_sent = sentiment_from_rating(rating)\n",
    "\n",
    "    pos = r5 + r4\n",
    "    neg = r1 + r2\n",
    "\n",
    "    dist_sent = \"Neutral\"\n",
    "    if pos > neg:\n",
    "        dist_sent = \"Positive\"\n",
    "    elif neg > pos:\n",
    "        dist_sent = \"Negative\"\n",
    "\n",
    "    for s in [text_sent, rating_sent, dist_sent]:\n",
    "        if s != \"Neutral\":\n",
    "            return s\n",
    "    return \"Neutral\"\n",
    "\n",
    "# ===============================\n",
    "# SELENIUM SETUP\n",
    "# ===============================\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "SEARCH_QUERY = \"Televisions\"\n",
    "TARGET_COUNT = 100\n",
    "CATEGORY = \"Electronics\"\n",
    "\n",
    "base_url = f\"https://www.flipkart.com/search?q={SEARCH_QUERY}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Close login popup\n",
    "try:\n",
    "    wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'âœ•')]\"))\n",
    "    ).click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = []\n",
    "seen_urls = set()\n",
    "page = 1\n",
    "saved_count = 0\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP (FIXED)\n",
    "# ===============================\n",
    "while saved_count < TARGET_COUNT:\n",
    "\n",
    "    print(f\"\\nðŸ”„ Page {page}\")\n",
    "\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollBy(0, 1500);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # âœ… WORKING SELECTOR\n",
    "    products = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//a[contains(@href,'/p/')]\"\n",
    "    )\n",
    "\n",
    "    print(\"Found products:\", len(products))\n",
    "\n",
    "    for a in products:\n",
    "        if saved_count >= TARGET_COUNT:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            link = a.get_attribute(\"href\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if not link or link in seen_urls:\n",
    "            continue\n",
    "        seen_urls.add(link)\n",
    "\n",
    "        try:\n",
    "            name = a.text.strip()\n",
    "            if not name:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Open product page\n",
    "        driver.execute_script(\"window.open(arguments[0]);\", link)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(4)\n",
    "\n",
    "        try:\n",
    "            price = driver.find_element(By.XPATH, \"//div[contains(text(),'â‚¹')]\").text\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            rating = driver.find_element(By.XPATH, \"//div[contains(@class,'MKiFS6')]\").text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        raw_review = \"\"\n",
    "        try:\n",
    "            blocks = driver.find_elements(By.XPATH, \"//div[contains(@class,'xgU6qg')]\")\n",
    "            raw_review = \"\\n\".join([b.text for b in blocks[:5]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        parsed = parse_review_block(raw_review)\n",
    "\n",
    "        if parsed[\"review_text\"] == \"No review available\":\n",
    "            parsed[\"review_text\"] = name\n",
    "\n",
    "        sentiment = hybrid_sentiment(\n",
    "            parsed[\"review_text\"],\n",
    "            parsed[\"overall_rating\"],\n",
    "            parsed[\"rating_5\"],\n",
    "            parsed[\"rating_4\"],\n",
    "            parsed[\"rating_1\"],\n",
    "            parsed[\"rating_2\"]\n",
    "        )\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        saved_count += 1\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": name,\n",
    "            \"product_price\": price,\n",
    "            \"overall_rating\": rating,\n",
    "            \"product_url\": link,\n",
    "            \"category\": CATEGORY\n",
    "        })\n",
    "\n",
    "        print(f\"âœ… Saved: {saved_count}\")\n",
    "\n",
    "    page += 1\n",
    "    driver.get(f\"{base_url}&page={page}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# ===============================\n",
    "# SAVE CSV\n",
    "# ===============================\n",
    "pd.DataFrame(results).to_csv(\n",
    "    \"televisions_dataset_flipkart.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nðŸŽ‰ DONE\")\n",
    "print(\"Clean file saved: Televisions_dataset_flipkart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966786f-b6b4-4c71-9767-a830200bb746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
